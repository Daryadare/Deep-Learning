{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7QYRRSvFNUL"
   },
   "source": [
    "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
    "\n",
    "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P59NYU98GCb9",
    "outputId": "d0067574-a9f1-4542-a1cb-1f39f4ed7c4f"
   },
   "outputs": [],
   "source": [
    "# !pip3 -qq install torch==0.4.1\n",
    "# !pip3 -qq install bokeh==0.13.0\n",
    "# !pip3 -qq install gensim==4.1.1\n",
    "# !pip3 -qq install nltk\n",
    "# !pip3 -qq install scikit-learn==0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8sVtGHmA9aBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6CNKM3b4hT1"
   },
   "source": [
    "# Рекуррентные нейронные сети (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_XkoGNQUeGm"
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFEtWrS_4rUs"
   },
   "source": [
    "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
    "\n",
    "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n",
    "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
    "\n",
    "Мы порешаем сейчас POS Tagging для английского.\n",
    "\n",
    "Будем работать с таким набором тегов:\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition (on, of, at, ...)\n",
    "- ADV - adverb (really, already, still, ...)\n",
    "- CONJ - conjunction (and, or, but, ...)\n",
    "- DET - determiner, article (the, a, some, ...)\n",
    "- NOUN - noun (year, home, costs, ...)\n",
    "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
    "- PRT - particle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- . - punctuation marks (. , ;)\n",
    "- X - other (ersatz, esprit, dunno, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPIkKdFlHB-X"
   },
   "source": [
    "Скачаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TiA2dGmgF1rW",
    "outputId": "63a806ac-e19b-4b34-f1ad-0c2f3153bf15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d93g_swyJA_V"
   },
   "source": [
    "Пример размеченного предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QstS4NO0L97c",
    "outputId": "65b7b201-7bcf-4291-9394-7c00e3d4c34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The            \tDET\n",
      "Fulton         \tNOUN\n",
      "County         \tNOUN\n",
      "Grand          \tADJ\n",
      "Jury           \tNOUN\n",
      "said           \tVERB\n",
      "Friday         \tNOUN\n",
      "an             \tDET\n",
      "investigation  \tNOUN\n",
      "of             \tADP\n",
      "Atlanta's      \tNOUN\n",
      "recent         \tADJ\n",
      "primary        \tNOUN\n",
      "election       \tNOUN\n",
      "produced       \tVERB\n",
      "``             \t.\n",
      "no             \tDET\n",
      "evidence       \tNOUN\n",
      "''             \t.\n",
      "that           \tADP\n",
      "any            \tDET\n",
      "irregularities \tNOUN\n",
      "took           \tVERB\n",
      "place          \tNOUN\n",
      ".              \t.\n"
     ]
    }
   ],
   "source": [
    "for word, tag in data[0]:\n",
    "    print('{:15}\\t{}'.format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epdW8u_YXcAv"
   },
   "source": [
    "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
    "\n",
    "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTai8Ta0lgwL",
    "outputId": "f246cd31-d299-4774-bd6a-dbfc9622c26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words count in train set: 739769\n",
      "Words count in val set: 130954\n",
      "Words count in test set: 290469\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
    "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
    "print('Words count in test set:', sum(len(sent) for sent in test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eChdLNGtXyP0"
   },
   "source": [
    "Построим маппинги из слов в индекс и из тега в индекс:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCjwwDs6Zq9x",
    "outputId": "591a2034-c4b4-43b9-ddfa-b65b84aad7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in train = 45441. Tags = {'DET', 'VERB', 'CONJ', 'PRT', 'ADV', 'X', '.', 'NUM', 'NOUN', 'ADP', 'ADJ', 'PRON'}\n"
     ]
    }
   ],
   "source": [
    "words = {word for sample in train_data for word, tag in sample}\n",
    "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
    "word2ind['<pad>'] = 0\n",
    "\n",
    "tags = {tag for sample in train_data for word, tag in sample}\n",
    "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
    "tag2ind['<pad>'] = 0\n",
    "\n",
    "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "URC1B2nvPGFt",
    "outputId": "6925e171-0ed0-4b24-ee91-10e8c8adbf7c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
    "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(tags)), tags)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gArQwbzWWkgi"
   },
   "source": [
    "## Бейзлайн\n",
    "\n",
    "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
    "\n",
    "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
    "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
    "\n",
    "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
    "\n",
    "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
    "\n",
    "Простейший вариант - униграммная модель, учитывающая только слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rWmSToIaeAo",
    "outputId": "755e323f-fd74-4408-e5b3-9d76500bfdbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of unigram tagger = 92.62%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.accuracy(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07Ymb_MkbWsF"
   },
   "source": [
    "Добавим вероятности переходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjz_Rk0bbMyH",
    "outputId": "1d0c46de-7814-4bfa-9d8b-00b4f27b80a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bigram tagger = 93.42%\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
    "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.accuracy(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWMw6QHvbaDd"
   },
   "source": [
    "Обратите внимание, что `backoff` важен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XCuxEBVbOY_",
    "outputId": "311362e0-9e26-4b25-fc58-26b8316a70de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trigram tagger = 23.33%\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_data)\n",
    "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.accuracy(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Om4tQUQslNm",
    "outputId": "013c61e8-cb49-414f-ef13-cf6fa25749a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trigram tagger = 93.43%\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_data, backoff=bigram_tagger)\n",
    "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.accuracy(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t3xyYd__8d-"
   },
   "source": [
    "## Увеличиваем контекст с рекуррентными сетями\n",
    "\n",
    "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
    "\n",
    "Омонимия - основная причина, почему униграмная модель плоха:  \n",
    "*“he cashed a check at the **bank**”*  \n",
    "vs  \n",
    "*“he sat on the **bank** of the river”*\n",
    "\n",
    "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
    "\n",
    "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
    "\n",
    "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
    "\n",
    "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RtRbz1SwgEqc"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, word2ind, tag2ind):\n",
    "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
    "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
    "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
    "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DhsTKZalfih6"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        \n",
    "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        \n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4XsRII5kW5x",
    "outputId": "6e4cac7d-e15e-4685-e26b-70fb90f87dda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 4), (32, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
    "\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5I9E9P6eFYv"
   },
   "source": [
    "**Задание** Реализуйте `LSTMTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "WVEHju54d68T"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb_out = self.emb(inputs)\n",
    "        lstm_out, _ = self.lstm(emb_out)\n",
    "        return self.lin(lstm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_HA8zyheYGH"
   },
   "source": [
    "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RtfSGU7f3Rbd"
   },
   "outputs": [],
   "source": [
    "def calculate_acc(y_batch, logits):\n",
    "    mask = (y_batch != 0).float()\n",
    "    preds = torch.argmax(logits, 2)\n",
    "  \n",
    "    current_count = ((preds == y_batch).float() * mask).sum()\n",
    "    total_count = mask.sum()\n",
    "\n",
    "    # for the 1 try\n",
    "#     return current_count / total_count\n",
    "\n",
    "    # for do_epoch()\n",
    "    return current_count, total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cFUiMfRG3ROe"
   },
   "outputs": [],
   "source": [
    "def calculate_loss(criterion, y_batch, logits):\n",
    "    return criterion(logits.transpose(2, 1), y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbrxsZ2mehWB",
    "outputId": "788e2e17-c493-41f2-d127-b090a14ef7bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0326\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "\n",
    "logits = model(X_batch)\n",
    "\n",
    "print('Accuracy: {:.3}'.format(calculate_acc(y_batch, logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMUyUm1hgpe3",
    "outputId": "e855d525-71c2-4c3b-ce40-dfbaa7bc77b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.6\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "print('Loss : {:.3}'.format(calculate_loss(criterion, y_batch, logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSgV3NPUpcjH"
   },
   "source": [
    "**Задание** Вставьте эти вычисление в функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FprPQ0gllo7b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "                logits = model(X_batch)\n",
    "\n",
    "                loss = calculate_loss(criterion, y_batch, logits)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                cur_correct_count, cur_sum_count = calculate_acc(y_batch, logits)\n",
    "\n",
    "                correct_count += cur_correct_count\n",
    "                sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pqfbeh1ltEYa",
    "outputId": "f03de76d-814a-4df0-f650-5b32ad1474b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 20] Train: Loss = 0.31892, Accuracy = 71.34%: 100%|██████████| 572/572 [00:04<00:00, 122.57it/s]\n",
      "[1 / 20]   Val: Loss = 0.09904, Accuracy = 85.54%: 100%|██████████| 13/13 [00:00<00:00, 75.51it/s]\n",
      "[2 / 20] Train: Loss = 0.10145, Accuracy = 89.80%: 100%|██████████| 572/572 [00:04<00:00, 129.75it/s]\n",
      "[2 / 20]   Val: Loss = 0.07082, Accuracy = 90.02%: 100%|██████████| 13/13 [00:00<00:00, 74.58it/s]\n",
      "[3 / 20] Train: Loss = 0.06803, Accuracy = 93.20%: 100%|██████████| 572/572 [00:04<00:00, 129.72it/s]\n",
      "[3 / 20]   Val: Loss = 0.06152, Accuracy = 91.29%: 100%|██████████| 13/13 [00:00<00:00, 74.14it/s]\n",
      "[4 / 20] Train: Loss = 0.05103, Accuracy = 94.80%: 100%|██████████| 572/572 [00:04<00:00, 117.01it/s]\n",
      "[4 / 20]   Val: Loss = 0.06076, Accuracy = 92.21%: 100%|██████████| 13/13 [00:00<00:00, 61.86it/s]\n",
      "[5 / 20] Train: Loss = 0.04075, Accuracy = 95.82%: 100%|██████████| 572/572 [00:04<00:00, 126.36it/s]\n",
      "[5 / 20]   Val: Loss = 0.06065, Accuracy = 92.67%: 100%|██████████| 13/13 [00:00<00:00, 74.97it/s]\n",
      "[6 / 20] Train: Loss = 0.03331, Accuracy = 96.53%: 100%|██████████| 572/572 [00:04<00:00, 128.48it/s]\n",
      "[6 / 20]   Val: Loss = 0.05572, Accuracy = 92.96%: 100%|██████████| 13/13 [00:00<00:00, 73.07it/s]\n",
      "[7 / 20] Train: Loss = 0.02747, Accuracy = 97.14%: 100%|██████████| 572/572 [00:04<00:00, 122.50it/s]\n",
      "[7 / 20]   Val: Loss = 0.06451, Accuracy = 93.19%: 100%|██████████| 13/13 [00:00<00:00, 76.25it/s]\n",
      "[8 / 20] Train: Loss = 0.02274, Accuracy = 97.63%: 100%|██████████| 572/572 [00:04<00:00, 121.05it/s]\n",
      "[8 / 20]   Val: Loss = 0.06090, Accuracy = 93.31%: 100%|██████████| 13/13 [00:00<00:00, 76.56it/s]\n",
      "[9 / 20] Train: Loss = 0.01890, Accuracy = 98.04%: 100%|██████████| 572/572 [00:04<00:00, 125.38it/s]\n",
      "[9 / 20]   Val: Loss = 0.06330, Accuracy = 93.41%: 100%|██████████| 13/13 [00:00<00:00, 69.40it/s]\n",
      "[10 / 20] Train: Loss = 0.01563, Accuracy = 98.37%: 100%|██████████| 572/572 [00:04<00:00, 122.38it/s]\n",
      "[10 / 20]   Val: Loss = 0.06518, Accuracy = 93.38%: 100%|██████████| 13/13 [00:00<00:00, 75.31it/s]\n",
      "[11 / 20] Train: Loss = 0.01300, Accuracy = 98.66%: 100%|██████████| 572/572 [00:04<00:00, 124.97it/s]\n",
      "[11 / 20]   Val: Loss = 0.06765, Accuracy = 93.40%: 100%|██████████| 13/13 [00:00<00:00, 74.97it/s]\n",
      "[12 / 20] Train: Loss = 0.01078, Accuracy = 98.90%: 100%|██████████| 572/572 [00:04<00:00, 124.78it/s]\n",
      "[12 / 20]   Val: Loss = 0.06905, Accuracy = 93.41%: 100%|██████████| 13/13 [00:00<00:00, 73.01it/s]\n",
      "[13 / 20] Train: Loss = 0.00869, Accuracy = 99.13%: 100%|██████████| 572/572 [00:04<00:00, 122.54it/s]\n",
      "[13 / 20]   Val: Loss = 0.06915, Accuracy = 93.31%: 100%|██████████| 13/13 [00:00<00:00, 74.81it/s]\n",
      "[14 / 20] Train: Loss = 0.00716, Accuracy = 99.30%: 100%|██████████| 572/572 [00:04<00:00, 125.64it/s]\n",
      "[14 / 20]   Val: Loss = 0.07455, Accuracy = 93.28%: 100%|██████████| 13/13 [00:00<00:00, 73.29it/s]\n",
      "[15 / 20] Train: Loss = 0.00590, Accuracy = 99.45%: 100%|██████████| 572/572 [00:04<00:00, 126.55it/s]\n",
      "[15 / 20]   Val: Loss = 0.07632, Accuracy = 93.21%: 100%|██████████| 13/13 [00:00<00:00, 47.27it/s]\n",
      "[16 / 20] Train: Loss = 0.00473, Accuracy = 99.56%: 100%|██████████| 572/572 [00:06<00:00, 92.32it/s] \n",
      "[16 / 20]   Val: Loss = 0.08588, Accuracy = 93.17%: 100%|██████████| 13/13 [00:00<00:00, 72.11it/s]\n",
      "[17 / 20] Train: Loss = 0.00378, Accuracy = 99.66%: 100%|██████████| 572/572 [00:04<00:00, 125.25it/s]\n",
      "[17 / 20]   Val: Loss = 0.08735, Accuracy = 93.10%: 100%|██████████| 13/13 [00:00<00:00, 73.40it/s]\n",
      "[18 / 20] Train: Loss = 0.00322, Accuracy = 99.71%: 100%|██████████| 572/572 [00:04<00:00, 120.65it/s]\n",
      "[18 / 20]   Val: Loss = 0.09250, Accuracy = 93.13%: 100%|██████████| 13/13 [00:00<00:00, 70.89it/s]\n",
      "[19 / 20] Train: Loss = 0.00266, Accuracy = 99.77%: 100%|██████████| 572/572 [00:04<00:00, 124.29it/s]\n",
      "[19 / 20]   Val: Loss = 0.09863, Accuracy = 93.10%: 100%|██████████| 13/13 [00:00<00:00, 71.72it/s]\n",
      "[20 / 20] Train: Loss = 0.00233, Accuracy = 99.79%: 100%|██████████| 572/572 [00:04<00:00, 125.65it/s]\n",
      "[20 / 20]   Val: Loss = 0.10197, Accuracy = 93.06%: 100%|██████████| 13/13 [00:00<00:00, 75.93it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# epochs_count=50 leads to overfitting\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0qGetIhfUE5"
   },
   "source": [
    "### Masking\n",
    "\n",
    "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
    "\n",
    "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAfV2dEOfHo5"
   },
   "source": [
    "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98wr38_rw55D",
    "outputId": "c2cb1857-a06d-401a-e717-74c5999e1842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0652\n",
      "Loss : 2.56\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "\n",
    "logits = model(X_batch)\n",
    "print('Accuracy: {:.3}'.format(calculate_acc(y_batch, logits)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "print('Loss : {:.3}'.format(calculate_loss(criterion, y_batch, logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXUTSFaEHbDG"
   },
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
    "\n",
    "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
    "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
    "\n",
    "**Задание** Добавьте Bidirectional LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Xk-0EBUKFNUc"
   },
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, \n",
    "                            lstm_layers_count, bidirectional=True)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim*2, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb_out = self.emb(inputs)\n",
    "        lstm_out, _ = self.lstm(emb_out)\n",
    "        return self.lin(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOE_4lH-9gxl",
    "outputId": "9329f754-d14d-4f32-c123-d4a7450c0529"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 5] Train: Loss = 0.55608, Accuracy = 82.50%: 100%|██████████| 572/572 [00:05<00:00, 104.13it/s]\n",
      "[1 / 5]   Val: Loss = 0.30969, Accuracy = 89.83%: 100%|██████████| 13/13 [00:00<00:00, 47.59it/s]\n",
      "[2 / 5] Train: Loss = 0.20584, Accuracy = 93.45%: 100%|██████████| 572/572 [00:05<00:00, 112.23it/s]\n",
      "[2 / 5]   Val: Loss = 0.21274, Accuracy = 93.24%: 100%|██████████| 13/13 [00:00<00:00, 49.66it/s]\n",
      "[3 / 5] Train: Loss = 0.13028, Accuracy = 95.94%: 100%|██████████| 572/572 [00:05<00:00, 103.52it/s]\n",
      "[3 / 5]   Val: Loss = 0.18606, Accuracy = 94.32%: 100%|██████████| 13/13 [00:00<00:00, 49.92it/s]\n",
      "[4 / 5] Train: Loss = 0.08909, Accuracy = 97.29%: 100%|██████████| 572/572 [00:05<00:00, 111.49it/s]\n",
      "[4 / 5]   Val: Loss = 0.15758, Accuracy = 95.09%: 100%|██████████| 13/13 [00:00<00:00, 46.40it/s]\n",
      "[5 / 5] Train: Loss = 0.06221, Accuracy = 98.15%: 100%|██████████| 572/572 [00:05<00:00, 103.60it/s]\n",
      "[5 / 5]   Val: Loss = 0.15267, Accuracy = 95.40%: 100%|██████████| 13/13 [00:00<00:00, 43.67it/s]\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=5,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTXmYGD_ANhm"
   },
   "source": [
    "### Предобученные эмбеддинги\n",
    "\n",
    "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
    "\n",
    "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "uZpY_Q1xZ18h",
    "outputId": "0809f5e9-0259-4177-aae7-9a0d2fcc8857"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYogOoKlgtcf"
   },
   "source": [
    "Построим подматрицу для слов из нашей тренировочной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "VsCstxiO03oT",
    "outputId": "977df007-0349-4b48-ca47-93d1616b7339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Know 38736 out of 45441 word embeddings\n"
     ]
    }
   ],
   "source": [
    "known_count = 0\n",
    "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
    "for word, ind in word2ind.items():\n",
    "    word = word.lower()\n",
    "    if word in w2v_model:\n",
    "        embeddings[ind] = w2v_model.get_vector(word)\n",
    "        known_count += 1\n",
    "        \n",
    "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.FloatTensor(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcG7i-R8hbY3"
   },
   "source": [
    "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LxaRBpQd0pat"
   },
   "outputs": [],
   "source": [
    "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
    "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings)\n",
    "        self.lstm = nn.LSTM(embeddings.shape[1], lstm_hidden_dim, lstm_layers_count)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb_out = self.emb(inputs)\n",
    "        lstm_out, _ = self.lstm(emb_out)\n",
    "        return self.lin(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EBtI6BDE-Fc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 15] Train: Loss = 0.75879, Accuracy = 78.06%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 41.05it/s]\n",
      "[1 / 15]   Val: Loss = 0.37370, Accuracy = 89.06%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 13.61it/s]\n",
      "[2 / 15] Train: Loss = 0.28644, Accuracy = 91.33%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 41.06it/s]\n",
      "[2 / 15]   Val: Loss = 0.25939, Accuracy = 91.93%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 13.17it/s]\n",
      "[3 / 15] Train: Loss = 0.21069, Accuracy = 93.35%: 100%|█████████████████████████████| 572/572 [00:14<00:00, 40.71it/s]\n",
      "[3 / 15]   Val: Loss = 0.21210, Accuracy = 93.27%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 13.40it/s]\n",
      "[4 / 15] Train: Loss = 0.17419, Accuracy = 94.43%: 100%|█████████████████████████████| 572/572 [00:14<00:00, 40.34it/s]\n",
      "[4 / 15]   Val: Loss = 0.18700, Accuracy = 94.02%: 100%|███████████████████████████████| 13/13 [00:01<00:00, 12.90it/s]\n",
      "[5 / 15] Train: Loss = 0.15307, Accuracy = 95.01%: 100%|█████████████████████████████| 572/572 [00:14<00:00, 40.61it/s]\n",
      "[5 / 15]   Val: Loss = 0.17114, Accuracy = 94.42%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 13.37it/s]\n",
      "[6 / 15] Train: Loss = 0.13919, Accuracy = 95.40%: 100%|█████████████████████████████| 572/572 [00:14<00:00, 40.33it/s]\n",
      "[6 / 15]   Val: Loss = 0.16054, Accuracy = 94.69%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 13.20it/s]\n",
      "[7 / 15] Train: Loss = 0.12920, Accuracy = 95.68%: 100%|█████████████████████████████| 572/572 [00:14<00:00, 40.30it/s]\n",
      "[7 / 15]   Val: Loss = 0.15501, Accuracy = 94.90%: 100%|███████████████████████████████| 13/13 [00:01<00:00, 12.44it/s]\n",
      "[8 / 15] Train: Loss = 0.12185, Accuracy = 95.88%: 100%|█████████████████████████████| 572/572 [00:14<00:00, 39.95it/s]\n",
      "[8 / 15]   Val: Loss = 0.14961, Accuracy = 95.01%: 100%|███████████████████████████████| 13/13 [00:01<00:00, 12.54it/s]\n",
      "[9 / 15] Train: Loss = 0.11607, Accuracy = 96.05%: 100%|█████████████████████████████| 572/572 [00:14<00:00, 39.67it/s]\n",
      "[9 / 15]   Val: Loss = 0.14628, Accuracy = 95.12%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 13.93it/s]\n",
      "[10 / 15] Train: Loss = 0.11146, Accuracy = 96.18%: 100%|████████████████████████████| 572/572 [00:14<00:00, 39.94it/s]\n",
      "[10 / 15]   Val: Loss = 0.14191, Accuracy = 95.29%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 13.68it/s]\n",
      "[11 / 15] Train: Loss = 0.10736, Accuracy = 96.29%: 100%|████████████████████████████| 572/572 [00:14<00:00, 39.27it/s]\n",
      "[11 / 15]   Val: Loss = 0.13993, Accuracy = 95.18%: 100%|██████████████████████████████| 13/13 [00:01<00:00, 12.87it/s]\n",
      "[12 / 15] Train: Loss = 0.10405, Accuracy = 96.41%: 100%|████████████████████████████| 572/572 [00:14<00:00, 39.24it/s]\n",
      "[12 / 15]   Val: Loss = 0.13830, Accuracy = 95.39%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 13.49it/s]\n",
      "[13 / 15] Train: Loss = 0.10109, Accuracy = 96.48%: 100%|████████████████████████████| 572/572 [00:14<00:00, 39.11it/s]\n",
      "[13 / 15]   Val: Loss = 0.14012, Accuracy = 95.21%: 100%|██████████████████████████████| 13/13 [00:01<00:00, 12.82it/s]\n",
      "[14 / 15] Train: Loss = 0.09858, Accuracy = 96.56%: 100%|████████████████████████████| 572/572 [00:14<00:00, 38.24it/s]\n",
      "[14 / 15]   Val: Loss = 0.13816, Accuracy = 95.37%: 100%|██████████████████████████████| 13/13 [00:01<00:00, 11.17it/s]\n",
      "[15 / 15] Train: Loss = 0.09629, Accuracy = 96.62%: 100%|████████████████████████████| 572/572 [00:14<00:00, 39.06it/s]\n",
      "[15 / 15]   Val: Loss = 0.13509, Accuracy = 95.32%: 100%|██████████████████████████████| 13/13 [00:01<00:00, 12.30it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTaggerWithPretrainedEmbs(\n",
    "    embeddings=embeddings,\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=15,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ne_8f24h8kg"
   },
   "source": [
    "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
    "\n",
    "Добейтесь качества лучше прошлых моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, test_data, batch_size):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    batches_count = math.ceil(len(test_data[0]) / batch_size)\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            \n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(test_data, batch_size)):\n",
    "                X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "                logits = model(X_batch)\n",
    "\n",
    "                loss = calculate_loss(criterion, y_batch, logits)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                cur_correct_count, cur_sum_count = calculate_acc(y_batch, logits)\n",
    "                correct_count += cur_correct_count\n",
    "                sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    loss.item(), cur_correct_count / cur_sum_count)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 2.57998, Accuracy = 4.92%: 100%|████████████████████████████████████████████████| 28/28 [00:01<00:00, 15.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.579976328781673, tensor(0.0492))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "test(model, criterion, test_data=(X_test, y_test), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
